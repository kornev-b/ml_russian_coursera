{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sklearn.cross_validation as cv\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "import operator\n",
    "\n",
    "def replace_col_withsum(data, name):\n",
    "    cols = data.columns[data.columns.str.contains(name)]\n",
    "    data[name] = data[cols[cols.str.contains('^r')]].sum(axis=1) - data[cols[cols.str.contains('^d')]].sum(axis=1)\n",
    "    data = data.drop(cols,axis=1)\n",
    "    return data\n",
    "\n",
    "def compute_additional_features(df):\n",
    "    df['total_level_r'] = 0\n",
    "    df['total_level_d'] = 0\n",
    "    df['total_xp_r'] = 0\n",
    "    df['total_xp_d'] = 0\n",
    "    df['total_gold_r'] = 0\n",
    "    df['total_gold_d'] = 0\n",
    "#     df['total_lh_r'] = 0\n",
    "#     df['total_lh_d'] = 0\n",
    "#     df['total_kills_r'] = 0\n",
    "#     df['total_kills_d'] = 0\n",
    "#     df['total_deaths_r'] = 0\n",
    "#     df['total_deaths_d'] = 0\n",
    "#     df['total_items_r'] = 0\n",
    "#     df['total_items_d'] = 0\n",
    "    for i in xrange(1, 6):\n",
    "        df['total_level_r'] += df['r%d_level' % i]\n",
    "        df['total_level_d'] += df['d%d_level' % i] \n",
    "        df['total_xp_r'] += df['r%d_xp' % i] \n",
    "        df['total_xp_d'] += df['d%d_xp' % i] \n",
    "        df['total_gold_r'] += df['r%d_gold' % i] \n",
    "        df['total_gold_d'] += df['d%d_gold' % i]\n",
    "#         df['total_lh_r'] += df['r%d_lh' % i] \n",
    "#         df['total_lh_d'] += df['d%d_lh' % i]\n",
    "#         df['total_kills_r'] += df['r%d_kills' % i] \n",
    "#         df['total_kills_d'] += df['d%d_kills' % i]\n",
    "#         df['total_deaths_r'] += df['r%d_deaths' % i] \n",
    "#         df['total_deaths_d'] += df['d%d_deaths' % i]\n",
    "#         df['total_items_r'] += df['r%d_items' % i] \n",
    "#         df['total_items_d'] += df['d%d_items' % i]\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    del df['duration']\n",
    "    del df['tower_status_radiant']\n",
    "    del df['tower_status_dire']\n",
    "    del df['barracks_status_radiant']\n",
    "    del df['barracks_status_dire']\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def delete_redundant_features(df):\n",
    "    for i in xrange(1, 6):\n",
    "        del df['r%d_level' % i]\n",
    "        del df['r%d_xp' % i]\n",
    "        del df['r%d_gold' % i]\n",
    "#         del df['r%d_lh' % i]\n",
    "#         del df['r%d_kills' % i]\n",
    "#         del df['r%d_deaths' % i]\n",
    "#         del df['r%d_items' % i]\n",
    "        del df['d%d_level' % i]\n",
    "        del df['d%d_xp' % i]\n",
    "        del df['d%d_gold' % i]\n",
    "#         del df['d%d_lh' % i]\n",
    "#         del df['d%d_kills' % i]\n",
    "#         del df['d%d_deaths' % i]\n",
    "#         del df['d%d_items' % i]\n",
    "    return df\n",
    "\n",
    "def categorize_lobbies(df):\n",
    "    X_pick = np.zeros((df.shape[0], 8))\n",
    "    for i, match_id in enumerate(df.index):\n",
    "        X_pick[i, df.ix[match_id, 'lobby_type']-1] = 1\n",
    "    \n",
    "    for i in xrange(8):\n",
    "        df['lobby_%d' % (i+1)] = X_pick[:, i]\n",
    "    del df['lobby_type']\n",
    "    return df\n",
    "    \n",
    "\n",
    "def categorize_heroes(df):\n",
    "    X_pick = np.zeros((df.shape[0], 112))\n",
    "\n",
    "    for i, match_id in enumerate(df.index):\n",
    "        for p in xrange(5):\n",
    "            X_pick[i, df.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X_pick[i, df.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "    for i in xrange(112):\n",
    "        df['hero_%d' % (i+1)] = X_pick[:, i]\n",
    "\n",
    "    for i in xrange(1, 6):\n",
    "        del df['r%d_hero' % i]\n",
    "        del df['d%d_hero' % i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Подготовка данных для NEAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 210)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv', index_col='match_id')\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "del df['start_time']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "print df.shape\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('features.csv', index_col='match_id')\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "del df['start_time']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = df[:df.shape[0]/3]\n",
    "train_target = target[:df.shape[0]/3]\n",
    "test = df.tail(df.shape[0]/10)\n",
    "test_target = target.tail(df.shape[0]/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32410, 211)\n",
      "(9723, 211)\n"
     ]
    }
   ],
   "source": [
    "# dummies_train = pd.get_dummies(train_target)\n",
    "ss = StandardScaler()\n",
    "data_train = ss.fit_transform(X=train, y=train_target)\n",
    "df_train = pd.DataFrame.from_records(data=data_train, columns=None)\n",
    "df_train = df_train.applymap(lambda x: '%.4f' % x)\n",
    "df_train['radiant_win'] = train_target.values\n",
    "print df_train.shape\n",
    "df_train.to_csv('clean_dota2_train', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "data_test = ss.transform(X=test)\n",
    "df_test = pd.DataFrame.from_records(data=data_test, columns=None)\n",
    "df_test = df_test.applymap(lambda x: '%.4f' % x)\n",
    "df_test['radiant_win'] = test_target.values\n",
    "print df_test.shape\n",
    "df_test.to_csv('clean_dota2_test', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "df = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "del df['start_time']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test = categorize_heroes(df_test)\n",
    "df_test = categorize_lobbies(df_test)\n",
    "\n",
    "del df_test['start_time']\n",
    "ss = StandardScaler()\n",
    "ss.fit_transform(X=df, y=target)\n",
    "data_test = ss.transform(X=df_test)\n",
    "df_test = pd.DataFrame.from_records(data=data_test, columns=None)\n",
    "df_test = df_test.applymap(lambda x: '%.4f' % x)\n",
    "df_test.to_csv('dota2_test', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 211)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv', index_col='match_id')\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "print df.shape\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 50, 10\n",
    "\n",
    "kf = cv.KFold(len(df.index), n_folds=4, shuffle=True, random_state=241)\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "clf = GradientBoostingClassifier(verbose=True, random_state=241)\n",
    "clf.fit(X=df, y=target)\n",
    "cv_res = cv.cross_val_score(clf, X=X_train, y=target, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "print \"CV Score : Mean - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_res),np.min(cv_res),np.max(cv_res))\n",
    "\n",
    "feat_imp = pd.Series(clf.feature_importances_, df.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "\n",
    "print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "print cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators':[50, 100, 200, 300], 'learning_rate':[0.1, 0.05, 0.01, 0.005]}\n",
    "clf = GradientBoostingClassifier(verbose=True, random_state=241,\n",
    "                                min_samples_split=500, min_samples_leaf=50, max_depth=8,\n",
    "                                max_features=14, subsample=0.8)\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = clf, param_grid = param_test1, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch1.fit(df, target)\n",
    "print gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d2_gold                 0.097737\n",
      "r2_gold                 0.095156\n",
      "r1_gold                 0.091634\n",
      "r4_gold                 0.090206\n",
      "d1_gold                 0.087771\n",
      "d5_gold                 0.087409\n",
      "d4_gold                 0.084650\n",
      "d3_gold                 0.079871\n",
      "r5_gold                 0.079143\n",
      "r3_gold                 0.070574\n",
      "first_blood_player1     0.055376\n",
      "radiant_boots_count     0.041018\n",
      "dire_boots_count        0.030568\n",
      "lobby_1                 0.004815\n",
      "d3_deaths               0.001155\n",
      "r4_lh                   0.000946\n",
      "d1_xp                   0.000927\n",
      "dire_first_ward_time    0.000643\n",
      "d2_lh                   0.000398\n",
      "d5_kills                0.000000\n",
      "radiant_courier_time    0.000000\n",
      "d5_deaths               0.000000\n",
      "d5_level                0.000000\n",
      "d5_items                0.000000\n",
      "first_blood_time        0.000000\n",
      "first_blood_team        0.000000\n",
      "d4_lh                   0.000000\n",
      "d5_lh                   0.000000\n",
      "d4_kills                0.000000\n",
      "d4_deaths               0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print feat_imp[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230, 211)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv', index_col=None)\n",
    "\n",
    "target = df['radiant_win']\n",
    "target = target.replace(0, -1)\n",
    "del df['radiant_win']\n",
    "del df['match_id']\n",
    "# del df['start_time']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "# df = replace_col_withsum(df, 'gold')\n",
    "# df = compute_additional_features(df)\n",
    "# df = delete_redundant_features(df)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X=df, y=target)\n",
    "X_new = X_train\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97230L, 211L)\n",
      "0    1\n",
      "1    1\n",
      "2   -1\n",
      "3   -1\n",
      "4   -1\n",
      "5   -1\n",
      "6   -1\n",
      "7    1\n",
      "8   -1\n",
      "9   -1\n",
      "Name: radiant_win, dtype: int64\n",
      "(97230L, 202L)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "# sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel = VarianceThreshold()\n",
    "X_new = sel.fit_transform(X_train) \n",
    "# lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X=X_train, y=target)\n",
    "# model = SelectFromModel(lsvc, prefit=True)\n",
    "# X_new = model.transform(X_train)\n",
    "print X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:18.772000\n",
      "[ 0.75346484  0.75175914  0.74852422  0.75316268]\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "kf = cv.KFold(X_new.shape[0], n_folds=4, shuffle=True, random_state=241)\n",
    "# tuned_parameters = {'C': [0.1, 0.5, 1, 10, 100, 1000], 'penalty':['l2']}\n",
    "# lr = GridSearchCV(LogisticRegression(random_state=241, n_jobs=-1), tuned_parameters, cv=5, scoring='roc_auc')\n",
    "lr = LogisticRegression(penalty='l2', random_state=241, n_jobs=-1, C=0.01)\n",
    "cs_result = cv.cross_val_score(lr, X=X_new, y=target, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "print cs_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('r2_lh', 1.4758462330384746e-18), ('dire_courier_time', 2.1571626310668795e-18), ('dire_first_ward_time', 2.3388827903533294e-18), ('dire_flying_courier_time', 2.8281786987678808e-18), ('radiant_first_ward_time', 3.078165159798031e-18), ('first_blood_time', 3.3964424869753729e-18), ('radiant_courier_time', 3.6662138618507246e-18), ('dire_bottle_time', 7.6522023149950535e-18), ('d1_xp', 1.3321481381295317e-17), ('d4_xp', 1.391119504376969e-17), ('d3_xp', 1.5156955525314047e-17), ('radiant_flying_courier_time', 1.6177215259048604e-17), ('d2_xp', 2.2612837523347719e-17), ('d5_xp', 2.4290806984599594e-17), ('d3_gold', 3.7567762443577028e-17), ('d4_gold', 4.0181070679393203e-17), ('d1_gold', 4.3550106257177432e-17), ('d5_gold', 4.4601177311346692e-17), ('d2_gold', 4.7130477737395722e-17), ('r3_xp', 9.5297815586561879e-17), ('r1_xp', 9.7988439655303937e-17), ('r4_xp', 1.0422103855610577e-16), ('r5_xp', 1.0538083714420889e-16), ('r2_xp', 1.0703779621761113e-16), ('r3_gold', 1.1562954103096547e-16), ('r4_gold', 1.190892854227111e-16), ('r5_gold', 1.2100684835023965e-16), ('r1_gold', 1.2394846711461367e-16), ('r2_gold', 1.2622721678426023e-16), ('start_time', 5.1366153162906341e-11)]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', random_state=241, n_jobs=-1, C=0.01)\n",
    "lr.fit(X=df, y=target) \n",
    "d ={}\n",
    "i = 0\n",
    "for col in df.columns.values:\n",
    "    d[col] = abs(lr.coef_[0][i])\n",
    "    i +=1\n",
    "s = sorted(d.items(), key=operator.itemgetter(1))\n",
    "print s[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12600284  0.87399716]\n",
      " [ 0.26256754  0.73743246]\n",
      " [ 0.73789737  0.26210263]\n",
      " [ 0.12893915  0.87106085]\n",
      " [ 0.67727228  0.32272772]\n",
      " [ 0.57853999  0.42146001]\n",
      " [ 0.46453849  0.53546151]\n",
      " [ 0.44879355  0.55120645]\n",
      " [ 0.7306638   0.2693362 ]\n",
      " [ 0.33605433  0.66394567]]\n",
      "max:  0.996185053309\n",
      "min:  0.00899150488956\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('features_test.csv', index_col=None)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test = categorize_heroes(df_test)\n",
    "df_test = categorize_lobbies(df_test)\n",
    "match_ids = df_test['match_id']\n",
    "del df_test['match_id']\n",
    "del df_test['start_time']\n",
    "X_test = ss.transform(X=df_test)\n",
    "lr.fit(X=X_train, y=target)\n",
    "predicted = lr.predict_proba(X_test)\n",
    "print predicted[:10]\n",
    "print 'max: ', max(predicted[:,1])\n",
    "print 'min: ', min(predicted[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id  radiant_win\n",
      "0         6     0.873997\n",
      "1         7     0.737432\n",
      "2        10     0.262103\n",
      "3        13     0.871061\n",
      "4        16     0.322728\n"
     ]
    }
   ],
   "source": [
    "d = {'match_id': match_ids, 'radiant_win': predicted[:,1]}\n",
    "df_result = pd.DataFrame(data=d, index=None)\n",
    "print df_result.head()\n",
    "df_result.to_csv('submission', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Feature transformations with ensembles of trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3781            4.98m\n",
      "         2           1.3722            5.00m\n",
      "         3           1.3671            5.00m\n",
      "         4           1.3621            4.99m\n",
      "         5           1.3569            5.09m\n",
      "         6           1.3523            5.32m\n",
      "         7           1.3481            5.35m\n",
      "         8           1.3437            5.36m\n",
      "         9           1.3395            5.35m\n",
      "        10           1.3354            5.26m\n",
      "        20           1.3045            4.84m\n",
      "        30           1.2828            4.54m\n",
      "        40           1.2664            4.32m\n",
      "        50           1.2535            4.12m\n",
      "        60           1.2427            4.02m\n",
      "        70           1.2334            3.83m\n",
      "        80           1.2252            3.63m\n",
      "        90           1.2176            3.45m\n",
      "       100           1.2110            3.26m\n",
      "       200           1.1614            1.62m\n",
      "       300           1.1268            0.00s\n",
      "0.732987595916\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('features.csv', index_col=None)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "target = df['radiant_win']\n",
    "target = target.replace(0, -1)\n",
    "del df['radiant_win']\n",
    "del df['match_id']\n",
    "# del df['start_time']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "train, test, train_target, test_target = train_test_split(df,\n",
    "                                                            target,\n",
    "                                                            test_size=0.1)\n",
    "\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(train,\n",
    "                                                            train_target,\n",
    "                                                            test_size=0.5)\n",
    "grd = GradientBoostingClassifier(n_estimators=300, random_state=241, verbose=True)\n",
    "grd_enc = OneHotEncoder()\n",
    "grd_lm = LogisticRegression(penalty='l2', random_state=241, n_jobs=-1, C=0.01)\n",
    "grd.fit(X_train, y_train)\n",
    "grd_enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "grd_lm.fit(grd_enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)\n",
    "\n",
    "y_pred_grd_lm = grd_lm.predict_proba(\n",
    "    grd_enc.transform(grd.apply(test)[:, :, 0]))[:, 1]\n",
    "print roc_auc_score(test_target, y_pred_grd_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### \"Активное обучение\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "df_orig = pd.read_csv('features.csv', index_col=None)\n",
    "df_test = pd.read_csv('features_test.csv', index_col=None)\n",
    "\n",
    "df = df_orig.copy()\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "del df['match_id']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)\n",
    "\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test = categorize_heroes(df_test)\n",
    "df_test = categorize_lobbies(df_test)\n",
    "match_ids = df_test['match_id']\n",
    "del df_test['match_id']\n",
    "ss.fit_transform(X=df, y=target)\n",
    "\n",
    "kf = cv.KFold(len(df.index), n_folds=4, shuffle=True, random_state=241)\n",
    "lr = LogisticRegression(penalty='l2', random_state=241, n_jobs=-1, C=0.1)\n",
    "\n",
    "train = df.values.tolist()\n",
    "target = target.tolist()\n",
    "test = df_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length:  97230\n",
      "target length:  97230\n",
      "test length:  17177\n",
      "[ 0.75340299  0.7517499   0.74853067  0.75302096]\n",
      "[[    0 16032]\n",
      " [    1  1145]]\n",
      "[[    0 16338]\n",
      " [    1   839]]\n",
      "Time elapsed: 0:00:35.299000\n",
      "train data length:  99214\n",
      "target length:  99214\n",
      "test length:  15193\n",
      "[ 0.75340303  0.75174967  0.74853069  0.75302077]\n",
      "[[    0 15107]\n",
      " [    1    86]]\n",
      "[[    0 15133]\n",
      " [    1    60]]\n",
      "Time elapsed: 0:00:34.645000\n"
     ]
    }
   ],
   "source": [
    "bound = 0.85\n",
    "for i in xrange(2):\n",
    "    start_time = datetime.datetime.now()\n",
    "    print \"train data length: \", len(train)\n",
    "    print \"target length: \", len(target)\n",
    "    print \"test length: \", len(test)\n",
    "    X_train = ss.fit_transform(X=train, y=target)\n",
    "    cs_result = cv.cross_val_score(lr, X=X_train, y=target, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "    print cs_result\n",
    "    X_test = ss.transform(X=test)\n",
    "    lr.fit(X=X_train, y=target)\n",
    "    predicted = lr.predict_proba(X_test)\n",
    "    radian_win = predicted[:,1] > bound\n",
    "    dire_win = predicted[:,0] > bound\n",
    "    del_ix = []\n",
    "    for i in xrange(len(predicted)):\n",
    "        if radian_win[i]: \n",
    "            train.append(test[i])\n",
    "            target.append(1)\n",
    "            del_ix.append(i)\n",
    "            # todo del from test\n",
    "        if dire_win[i]:\n",
    "            train.append(test[i])\n",
    "            target.append(0)\n",
    "            del_ix.append(i)\n",
    "            # todo del from test\n",
    "    for i in sorted(del_ix, reverse=True):\n",
    "        del test[i]\n",
    "    unique, counts = np.unique(predicted[:,1] > bound, return_counts=True)\n",
    "    print np.asarray((unique, counts)).T\n",
    "    unique, counts = np.unique(predicted[:,0] > bound, return_counts=True)\n",
    "    print np.asarray((unique, counts)).T\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99360\n",
      "99360\n",
      "[[ 0.48037768  0.51962232]\n",
      " [ 0.4803776   0.5196224 ]\n",
      " [ 0.48037749  0.51962251]\n",
      " [ 0.48037718  0.51962282]\n",
      " [ 0.48037708  0.51962292]\n",
      " [ 0.48037704  0.51962296]\n",
      " [ 0.48037703  0.51962297]\n",
      " [ 0.48037683  0.51962317]\n",
      " [ 0.4803766   0.5196234 ]\n",
      " [ 0.48037648  0.51962352]]\n",
      "   match_id  radiant_win\n",
      "0         6     0.519622\n",
      "1         7     0.519622\n",
      "2        10     0.519623\n",
      "3        13     0.519623\n",
      "4        16     0.519623\n"
     ]
    }
   ],
   "source": [
    "print len(train)\n",
    "print len(target)\n",
    "lr.fit(X=train, y=target)\n",
    "predicted = lr.predict_proba(df_test)\n",
    "print predicted[:10]\n",
    "d = {'match_id': match_ids, 'radiant_win': predicted[:,1]}\n",
    "df_result = pd.DataFrame(data=d, index=None)\n",
    "print df_result.head()\n",
    "df_result.to_csv('submission', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('features.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1430220345.0, 0.0, 42.0, 4.0, 1188.0, 1033.0, 9.0, 0.0, 1.0, 12.0, 49.0, 4.0, 1596.0, 993.0, 10.0, 0.0, 1.0, 7.0, 67.0, 4.0, 1506.0, 1502.0, 18.0, 1.0, 0.0, 7.0, 37.0, 3.0, 669.0, 631.0, 7.0, 0.0, 0.0, 7.0, 26.0, 2.0, 415.0, 539.0, 1.0, 0.0, 0.0, 5.0, 39.0, 5.0, 1960.0, 1384.0, 16.0, 0.0, 0.0, 8.0, 88.0, 3.0, 640.0, 566.0, 1.0, 0.0, 1.0, 5.0, 79.0, 3.0, 720.0, 1350.0, 2.0, 2.0, 0.0, 12.0, 7.0, 2.0, 440.0, 583.0, 0.0, 0.0, 0.0, 7.0, 12.0, 4.0, 1470.0, 1622.0, 24.0, 0.0, 0.0, 9.0, 54.0, 1.0, 7.0, nan, 173.0, -80.0, nan, 2.0, 0.0, 2.0, 0.0, -20.0, 149.0, -84.0, 195.0, 5.0, 4.0, 3.0, 1.0, -5.0, 2463.0, 1.0, 1974.0, 0.0, 63.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = df.values.tolist()\n",
    "print a[1]\n",
    "# print df.head()\n",
    "# todel = []\n",
    "# todel.append(1)\n",
    "# todel.append(3)\n",
    "# df.drop(df.index[[todel]], inplace=True)\n",
    "# print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "df = pd.read_csv('features.csv', index_col=None)\n",
    "\n",
    "target = df['radiant_win']\n",
    "del df['radiant_win']\n",
    "del df['match_id']\n",
    "\n",
    "df = preprocess(df)\n",
    "df = categorize_heroes(df)\n",
    "df = categorize_lobbies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:08:57.187000\n",
      "[ 0.71043932  0.71114338  0.70850037  0.71039338]\n"
     ]
    }
   ],
   "source": [
    "forest = ExtraTreesClassifier(n_estimators=500,\n",
    "                              n_jobs=-1,\n",
    "                              random_state=241,\n",
    "                              verbose=True)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "cs = cv.cross_val_score(forest, X=df, y=target, cv=kf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "print cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest.fit_transform(X=df, y=target)\n",
    "\n",
    "df_test = pd.read_csv('features_test.csv', index_col=None)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test = categorize_heroes(df_test)\n",
    "df_test = categorize_lobbies(df_test)\n",
    "match_ids = df_test['match_id']\n",
    "del df_test['match_id']\n",
    "\n",
    "predicted = forest.predict_proba(X=df_test)\n",
    "print predicted[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
